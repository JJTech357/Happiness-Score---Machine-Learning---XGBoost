ðŸ§  Predicting Happiness: A Well-being Regression Model1. Project Title and DescriptionThis project develops a machine learning model to predict an individual's "happiness score" based on a comprehensive life and well-being survey.Using Multiple Linear Regression (MLR) in R, the model analyzes demographic, socio-economic, and psychological factors to understand and quantify their impact on the final continuous happiness score. The goal is to build an accurate and interpretable model that establishes a baseline for predicting individual well-being.2. Table of ContentsProject Title and DescriptionTable of ContentsInstallation InstructionsDataset DescriptionModeling ApproachResults and EvaluationUsageProject StructureContributing GuidelinesLicense3. Installation InstructionsThis project is implemented in R and executed within a Jupyter Notebook environment (using an R kernel).PrerequisitesR Environment: Ensure R (version 3.6.3 or newer is recommended) is installed.Jupyter: Install Jupyter Notebook/JupyterLab.IRKernel: Install and configure the R kernel for Jupyter:Bash# In R console:
install.packages('IRkernel')
IRkernel::installspec()
Required R PackagesInstall the following packages in your R environment:Rinstall.packages(c(
    "dplyr",
    "tidyr",
    "performance",
    "visreg",
    "fastDummies",
    "caret",
    "nnet",
    "xgboost"
))
Running the NotebookClone the repository:Bashgit clone [Your Repository URL]
cd [Your Repository Name]
Place the required data files (regression_train.csv and regression_test.csv) into the root directory.Launch Jupyter Notebook:Bashjupyter notebook
Open and run the notebook: FIT5197_FinalAssessment (1).ipynb. Select the R kernel.4. Dataset DescriptionSource FilesThe model uses two primary datasets, assumed to be provided separately from the repository:regression_train.csv: Training data with all predictor variables and the target variable (happiness).regression_test.csv: Test data with only predictor variables, used for prediction.FeaturesThe dataset consists of over 40 features derived from survey questions, including:Feature TypeExamplesDescriptionTarget VariablehappinessA continuous numerical score representing the individual's happiness level.Categoricalgender, income, whatIsYourHeight...Factors with multiple levels (e.g., income ranges, height bands).Ordinal/NumericalwaysAnxious, alwaysStressed, iFindBeautyInSomeThingsSelf-assessment scores on a scale, typically ranging from -2 to +2.PreprocessingHandling Categorical Variables: The primary Multiple Linear Regression model (lm) automatically handles factor variables by creating dummy (one-hot) encoded features, while avoiding multicollinearity by dropping the first level (reference category).Feature Mapping (Exploration): The notebook includes code blocks for manual ordinal encoding of variables like income and height into a single numeric value for exploratory analysis and alternative models.5. Modeling ApproachAlgorithmThe core model for happiness score prediction is Multiple Linear Regression (MLR).RationaleMLR was chosen as the initial approach due to its interpretability. By examining the model coefficients and their statistical significance (p-values), we can directly quantify the direction and magnitude of the relationship between each predictor and the happiness score.Model DevelopmentFull Model (lm.fit): An initial model was trained using all available features (both categorical and numeric).Rlm.fit <- lm(happiness ~ ., data=train)
Feature Selection: Predictors with a statistical significance of $p \le 0.01$ were identified to understand the core drivers of happiness.Model Comparison: The full model was compared against a simpler model that excluded all categorical variables to determine the value added by socio-economic and demographic data.6. Results and EvaluationPerformance MetricsThe model was evaluated using Root Mean Squared Error (RMSE), which measures the average magnitude of the errors.ModelDescriptionRMSE (Training Data)lm.fit (Full MLR)Includes all features (categorical and numeric)4.250579lm.fit2 (Numeric Only)Excludes all categorical features4.693674The Full MLR Model provided the superior performance, indicating that the categorical features (especially income) are crucial predictors.Key PredictorsBased on the absolute t-value (which indicates the strength of the association), the strongest predictors for the happiness score in the full model were predominantly income-related variables:income80k - 120kincome50k - 80kincome200k aboveincome20k - 50kincome15k - 20k7. UsageThis model can be used as a baseline for predicting continuous well-being scores in similar survey datasets. To adapt the model:Feature Engineering: If using a new dataset, ensure categorical features are correctly recognized as factors in R to allow for implicit dummy encoding by the lm() function.Retraining: Use the same lm(happiness ~ ., data=new_train_data) structure for initial training.Advanced Models: This MLR approach provides a highly interpretable result. For potentially better performance, the methodology can be extended to implement more complex models like XGBoost (eXtreme Gradient Boosting) or Neural Networks (nnet), for which required packages are included in the setup.8. Project Structure.
â”œâ”€â”€ FIT5197_FinalAssessment (1).ipynb  # R Jupyter Notebook with code, analysis, and models.
â”œâ”€â”€ 32455038-final-assignment.pdf      # Detailed report/explanation of the project and results.
â”œâ”€â”€ regression_train.csv               # (Data - not included in repo, required to run)
â”œâ”€â”€ regression_test.csv                # (Data - not included in repo, required to run)
â””â”€â”€ README.md                          # This file.

9. Contributing GuidelinesContributions are welcome! Please open an issue first to discuss the desired changes or enhancements.
