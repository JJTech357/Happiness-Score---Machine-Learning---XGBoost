üéØ Happiness Score Prediction ModelThis repository contains the machine learning model developed to predict an individual's happiness score based on a comprehensive life and well-being survey dataset.The solution uses a Multiple Linear Regression (MLR) model in R to analyze the relationship between various demographic, psychological, and lifestyle factors and the final happiness score.üìä DatasetThe model was trained on the regression_train.csv dataset derived from a large-scale life and well-being survey.Target Variable: happiness (a continuous numerical score).Predictor Variables: Over 40 variables, including categorical factors like gender and income, and scale-based self-assessment scores (e.g., alwaysAnxious, alwaysCalm, iFindBeautyInSomeThings) on a scale of -2 to 2.üíª Modeling ApproachThe final model selection was based on a comparative analysis of different linear regression approaches, using the Root Mean Squared Error (RMSE) as the primary evaluation metric.1. Model TypeModel: Multiple Linear Regression (MLR)Language/Environment: R within a Jupyter Notebook environment.2. Feature Engineering & SelectionAn initial MLR model using all available predictor variables (including one-hot encoding for categorical features handled by R's lm() function) demonstrated the strongest performance.Categorical Variables: Handled as-is by the lm() function, effectively generating dummy variables.Feature Selection: An analysis identified 26 predictors (at a p-value $\le 0.01$) that are statistically associated with the happiness score.üß† Key Findings & PerformanceTop 5 Strongest PredictorsThe strength of a predictor was determined by the absolute value of its t-statistic in the full MLR model. The most impactful features for predicting happiness were all related to income (compared to the baseline/omitted income category):income80k - 120kincome50k - 80kincome200k aboveincome20k - 50kincome15k - 20kModel Performance (on Training Data)The final model (lm.fit) incorporating all features achieved the following performance metrics:MetricValueRoot Mean Squared Error (RMSE)4.250579Mean Squared Error (MSE)18.06733This performance was superior to a simpler model that excluded all categorical variables (which had an RMSE of 4.693674), confirming the importance of including demographic and lifestyle categories in the prediction.üõ†Ô∏è How to RunThe model development is fully documented in the provided Jupyter Notebook.Dependencies (R Packages)The analysis requires the following R libraries to be installed:Rlibrary(dplyr)
library(tidyr)
library(performance)
library(visreg)
library(fastDummies)
library(caret)
library(nnet)
library(xgboost)
ExecutionEnsure you have an R kernel configured for your Jupyter Notebook environment.Place the regression_train.csv and regression_test.csv files in the working directory.Run the cells in the FIT5197_FinalAssessment (1).ipynb notebook sequentially to load data, perform EDA, train the model, and evaluate performance.
